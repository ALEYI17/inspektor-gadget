---
title: cuda_metrics
sidebar_position: 0
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# cuda_metrics

Collect aggregated metrics about CUDA workloads, including kernel launches, execution time, memory allocations, and memory copy operations.

## Requirements

- The CUPTI userspace library must be installed.  
  Follow the instructions in:

```

inspektor-gadget/gadgets/trace_cuda/cupti/README.md

````

Without the CUPTI library, only memory allocation and memory copy metrics will be available.

- NVIDIA drivers must be installed.
- CUDA runtime libraries must be available.

## Getting started

Running the gadget:

<Tabs groupId="env">
    <TabItem value="kubectl-gadget" label="kubectl gadget">
        ```bash
        $ kubectl gadget run ghcr.io/inspektor-gadget/gadget/cuda_metrics:%IG_TAG% [flags]
        ```
    </TabItem>

    <TabItem value="ig" label="ig">
        ```bash
        $ sudo ig run ghcr.io/inspektor-gadget/gadget/cuda_metrics:%IG_TAG% [flags]
        ```
    </TabItem>
</Tabs>

## Flags

### `--host`

Collect metrics from host processes in addition to containers.

## Description

`cuda_metrics` collects aggregated statistics about CUDA activity in running workloads.

It provides visibility into:

### Launch Kernel Metrics

Metrics related to CUDA kernel launches:

* **`kernel_launches`**
  Total number of kernel launch attempts.

* **`block_threads_hist`**
  Histogram of threads per block.

* **`grid_blocks_hist`**
  Histogram of blocks per grid.

* **`total_threads_hist`**
  Histogram of total threads per kernel launch

* **`kernel_execution_time_hist`**
  Histogram of kernel execution time (in nanoseconds).

  Requires the CUPTI userspace library.


### Memory Allocation Metrics

Metrics related to CUDA device memory allocations:

* **`num_memalloc`**
  Total number of device memory allocation attempts.

* **`total_mem_alloc`**
  Total number of bytes successfully allocated on the device.


### Memory Copy Metrics

Metrics related to CUDA memory transfers:

* **`num_memcpy_htod`**
  Number of Host → Device memory copy operations.

* **`num_memcpy_dtoh`**
  Number of Device → Host memory copy operations.

* **`memcpy_htod_bytes`**
  Total bytes transferred from Host → Device.

* **`memcpy_dtoh_bytes`**
  Total bytes transferred from Device → Host.


### Error Metrics

Metrics tracking failed CUDA operations:

* **`kernel_launch_errors`**
  Number of failed kernel launches.

* **`mem_alloc_errors`**
  Number of failed device memory allocations.

* **`memcpy_htod_errors`**
  Number of failed Host → Device memory copies.

* **`memcpy_dtoh_errors`**
  Number of failed Device → Host memory copies.



## Guide
### 1. Install the CUPTI library

First, build and install the required CUPTI userspace library by following the instructions in:

````

inspektor-gadget/gadgets/trace_cuda/cupti/README.md

````

### 2. Run the gadget

Start the gadget using one of the commands shown in the *Getting started* section.

### 3. Run a sample CUDA application

You can test the gadget using a simple CUDA program such as the following SAXPY example:

```bash
cat << EOF > saxpy.cu
#include <stdio.h>
#include <stdlib.h>
#include <math.h>

__global__
void saxpy(int n, float a, float *x, float *y)
{
  int i = blockIdx.x * blockDim.x + threadIdx.x;
  if (i < n)
    y[i] = a * x[i] + y[i];
}

int main(void)
{
  int N = 1<<20;
  float *x, *y, *d_x, *d_y;

  x = (float*)malloc(N * sizeof(float));
  y = (float*)malloc(N * sizeof(float));

  cudaMalloc(&d_x, N * sizeof(float));
  cudaMalloc(&d_y, N * sizeof(float));

  for (int i = 0; i < N; i++) {
    x[i] = 1.0f;
    y[i] = 2.0f;
  }

  cudaMemcpy(d_x, x, N * sizeof(float), cudaMemcpyHostToDevice);
  cudaMemcpy(d_y, y, N * sizeof(float), cudaMemcpyHostToDevice);

  // Perform SAXPY on 1M elements
  saxpy<<<(N + 255) / 256, 256>>>(N, 2.0f, d_x, d_y);

  cudaMemcpy(y, d_y, N * sizeof(float), cudaMemcpyDeviceToHost);

  float maxError = 0.0f;
  for (int i = 0; i < N; i++)
    maxError = fmax(maxError, fabs(y[i] - 4.0f));

  printf("Max error: %f\n", maxError);

  cudaFree(d_x);
  cudaFree(d_y);
  free(x);
  free(y);
}
EOF
````

Compile and run it:

```bash
nvcc saxpy.cu -o saxpy
./saxpy
```

## Export Prometheus Metrics

To export CUDA metrics via OpenTelemetry:

````
kubectl gadget run ghcr.io/inspektor-gadget/gadget/cuda_metrics \
--name cudametrics \
--annotate=gpu_metrics:metrics.collect=true \
--otel-metrics-name=gpu_metrics:cuda-metrics
````

## Retrieving Metrics

After starting the gadget:

````
POD_NAME=$(kubectl get pods -n gadget -o jsonpath="{.items[0].metadata.name}")
kubectl -n gadget port-forward $POD_NAME 2224:2224 &
curl http://localhost:2224/metrics -s | grep cuda
````

## Notes
- `cuda_metrics` provides aggregated statistics, while trace_cuda provides per event visibility.
- Kernel execution time metrics require the CUPTI userspace library.
